{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, element_at, when\n",
    "import json\n",
    "import pandas as pd\n",
    "import pygeohash as pgh\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x7f3a5fb42d40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient ()\n",
    "db = client.fit3182_assignment_db\n",
    "climate_stream = db.climate_stream\n",
    "climate_stream.delete_many({})\n",
    "\n",
    "aqua_stream = db.aqua_stream\n",
    "aqua_stream.delete_many({})\n",
    "\n",
    "terra_stream = db.terra_stream\n",
    "terra_stream.delete_many({})\n",
    "\n",
    "merged_stream = db.merged_stream\n",
    "merged_stream.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = 'Assignment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .appName('[Demo] Spark Streaming from Kafka into MongoDB')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_stream_df = (\n",
    "    spark.readStream.format('kafka')\n",
    "    .option('kafka.bootstrap.servers', 'localhost:9092')\n",
    "    .option('subscribe', topic_name)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_stream_df = (\n",
    "    topic_stream_df\n",
    "    .select(                                      # 1\n",
    "            topic_stream_df.value.cast('string')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_climate_data():\n",
    "    climate_stream_data = climate_stream.find()\n",
    "    climate_stream_data = list(climate_stream_data)\n",
    "    climate_stream_data = pd.DataFrame(climate_stream_data)\n",
    "    climate_stream_data[[\"latitude\",\"longitude\"]]= climate_stream_data[[\"latitude\",\"longitude\"]].astype(float)\n",
    "    climate_stream_data[\"encode_location\"] = climate_stream_data.apply(lambda x: pgh.encode(x.latitude, x.longitude, precision=3), axis=1)\n",
    "    climate_stream_data = climate_stream_data.to_dict(orient='records')\n",
    "    climate_stream.delete_many({})\n",
    "    climate_stream.insert_many(climate_stream_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aqua_data():\n",
    "    aqua_stream_data = aqua_stream.find()\n",
    "    aqua_stream_data = list(aqua_stream_data)\n",
    "    aqua_stream_data = pd.DataFrame(aqua_stream_data)\n",
    "    aqua_stream_data[[\"latitude\",\"longitude\"]]= aqua_stream_data[[\"latitude\",\"longitude\"]].astype(float)\n",
    "    aqua_stream_data[\"encode_location\"] = aqua_stream_data.apply(lambda x: pgh.encode(x.latitude, x.longitude, precision=3), axis=1)\n",
    "    aqua_stream_data[\"encode_location_pre\"] = aqua_stream_data.apply(lambda x: pgh.encode(x.latitude, x.longitude, precision=5), axis=1)\n",
    "    aqua_stream_data = aqua_stream_data.to_dict(orient='records')\n",
    "    aqua_stream.delete_many({})\n",
    "    aqua_stream.insert_many(aqua_stream_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_terra_data():\n",
    "    terra_stream_data = terra_stream.find()\n",
    "    terra_stream_data = list(terra_stream_data)\n",
    "    terra_stream_data = pd.DataFrame(terra_stream_data)\n",
    "    terra_stream_data[[\"latitude\",\"longitude\"]]=terra_stream_data[[\"latitude\",\"longitude\"]].astype(float)\n",
    "    terra_stream_data[\"encode_location\"] = terra_stream_data.apply(lambda x: pgh.encode(x.latitude, x.longitude, precision=3), axis=1)\n",
    "    terra_stream_data[\"encode_location_pre\"] = terra_stream_data.apply(lambda x: pgh.encode(x.latitude, x.longitude, precision=5), axis=1)\n",
    "    terra_stream_data = terra_stream_data.to_dict(orient='records')\n",
    "    terra_stream.delete_many({})\n",
    "    terra_stream.insert_many(terra_stream_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fire_cause():\n",
    "    merged_stream_data = merged_stream.find()\n",
    "    merged_stream_data = list(merged_stream_data)\n",
    "    merged_stream_data = pd.DataFrame(merged_stream_data)\n",
    "\n",
    "    for i in range(merged_stream_data.shape[0]):\n",
    "        if type(merged_stream_data['Hotspot'][i]) == list:\n",
    "            if merged_stream_data['air_temperature_celcius'][i] > 20 and merged_stream_data['GHI_w/m2'][i] > 180 :\n",
    "                merged_stream_data.loc[i,'fire_cause'] = \"natural\"\n",
    "            else:\n",
    "                merged_stream_data.loc[i,'fire_cause'] = \"other\"\n",
    "        else:\n",
    "            merged_stream_data.loc[i,'fire_cause'] = None\n",
    "            \n",
    "    merged_stream_data = merged_stream_data.to_dict(orient='records')\n",
    "    merged_stream.delete_many({})\n",
    "    merged_stream.insert_many(merged_stream_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_compare():\n",
    "    merged_stream_data = merged_stream.find()\n",
    "    merged_stream_data = list(merged_stream_data)\n",
    "    merged_stream_data = pd.DataFrame(merged_stream_data)\n",
    "\n",
    "\n",
    "    hotspots = merged_stream_data['Hotspot']\n",
    "\n",
    "\n",
    "    for i in range(len(hotspots)):\n",
    "        if type(hotspots[i]) == list:\n",
    "            hotspots_list = hotspots[i]\n",
    "            if len(hotspots_list) > 1:\n",
    "                for j in range(0, len(hotspots_list)-2):\n",
    "                    if hotspots_list[j]['encode_location_pre'] == hotspots_list[j+1]['encode_location_pre']:\n",
    "                        hotspots_list[j]['confidence'] = (int(hotspots_list[j]['confidence']) + int(hotspots_list[j+1]['confidence'])) / 2\n",
    "                        hotspots_list[j]['surface_temperature_celcius'] = (int(hotspots_list[j]['surface_temperature_celcius']) + int(hotspots_list[j+1]['surface_temperature_celcius'])) / 2\n",
    "                        hotspots_list.pop(j+1)\n",
    "\n",
    "    merged_stream_data['Hotspot'] = hotspots\n",
    "    merged_stream_data = merged_stream_data.to_dict(orient='records')\n",
    "    merged_stream.delete_many({})\n",
    "    merged_stream.insert_many(merged_stream_data)\n",
    "    process_fire_cause()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupdata():\n",
    "    climate_stream_data = climate_stream.find()\n",
    "    climate_stream_data = list(climate_stream_data)\n",
    "\n",
    "    aqua_stream_data = aqua_stream.find()\n",
    "    aqua_stream_data = list(aqua_stream_data)\n",
    "    \n",
    "    terra_stream_data = terra_stream.find()\n",
    "    terra_stream_data = list(terra_stream_data)\n",
    "    \n",
    "    \n",
    "    if len(climate_stream_data) > 0 and len(aqua_stream_data) and len(terra_stream_data) > 0:\n",
    "        climate_stream_data = pd.DataFrame(climate_stream_data)\n",
    "        aqua_stream_data = pd.DataFrame(aqua_stream_data)\n",
    "        terra_stream_data = pd.DataFrame(terra_stream_data)\n",
    "        \n",
    "        merge_hotspot = [aqua_stream_data,terra_stream_data]\n",
    "        merge_hotspot = pd.concat(merge_hotspot)\n",
    "        \n",
    "        grouped = ( merge_hotspot.groupby(['encode_location'])\n",
    "                              .apply(lambda x: x[['latitude','longitude','datetime', 'confidence','surface_temperature_celcius','key','encode_location_pre']].to_dict('r'))\n",
    "                              .reset_index()\n",
    "                              .rename(columns={0:'Hotspot'}))\n",
    "        \n",
    "        df = climate_stream_data.merge(grouped, on = 'encode_location', how = 'left')\n",
    "        \n",
    "        merged_data = df.to_dict(orient='records')\n",
    "        merged_stream.delete_many({})\n",
    "        merged_stream.insert_many(merged_data)\n",
    "        process_compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df,batch_id):\n",
    "    raw_data = batch_df.collect()\n",
    "    \n",
    "\n",
    "    for x in raw_data:\n",
    "        str_data = x.asDict()\n",
    "        json_data = json.loads(str_data['value']) \n",
    "        if json_data['key'] == 'Producer01':\n",
    "            climate_stream.insert_one(json_data)\n",
    "            process_climate_data()\n",
    "        elif json_data['key'] == 'Producer02':\n",
    "            aqua_stream.insert_one(json_data)\n",
    "            process_aqua_data()\n",
    "            groupdata()\n",
    "\n",
    "        else:\n",
    "            terra_stream.insert_one(json_data)\n",
    "            process_terra_data()\n",
    "            groupdata()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_writer = (\n",
    "    output_stream_df\n",
    "    .writeStream\n",
    "    .outputMode('append')\n",
    "    .trigger(processingTime='10 seconds')\n",
    "    .foreachBatch(process_batch)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    query = db_writer.start()\n",
    "    query.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted by CTRL-C. Stopped query')\n",
    "except StreamingQueryException as exc:\n",
    "    print(exc)\n",
    "finally:\n",
    "    query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
